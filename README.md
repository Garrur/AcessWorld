# AccessWorld â€” Real-Time Environment Describer for Visually Impaired ğŸŒ

> **285 million** visually impaired people struggle with daily navigation. AccessWorld gives them a voice-first, hands-free AI companion that describes the world around them in real time.

---

## ğŸš€ Demo Pipeline

```
ğŸ¤ Speak â†’ ğŸ‘ï¸ Caption â†’ ğŸ“¦ Detect â†’ ğŸ“ Depth â†’ ğŸŒ Translate â†’ ğŸ”Š Speak
```

| Step | Model | Task |
|---|---|---|
| ğŸ¤ ASR | `openai/whisper-base` | Voice â†’ Text (hands-free) |
| ğŸ‘ï¸ Caption | `Salesforce/blip-image-captioning-large` | Image â†’ Description |
| ğŸ“¦ Detection | `facebook/detr-resnet-50` | Object detection + bboxes |
| ğŸ“ Depth | `Intel/dpt-large` | 3-zone proximity map |
| ğŸ”Š TTS | `microsoft/speecht5_tts` + `speecht5_hifigan` | Text â†’ Natural speech |
| ğŸŒ Translate | `Helsinki-NLP/opus-mt-en-{hi,fr,es,de,zh}` | 5 languages |

All models are **free, open-source, and run locally** â€” zero API cost.

---

## ğŸ“ Project Structure

```
Accessworld/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                # FastAPI app entry point
â”‚   â”œâ”€â”€ pipeline.py            # End-to-end AI pipeline orchestrator
â”‚   â”œâ”€â”€ download_models.py     # Pre-download all HF models
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ whisper.py         # Whisper ASR
â”‚   â”‚   â”œâ”€â”€ captioner.py       # BLIP-Large
â”‚   â”‚   â”œâ”€â”€ detector.py        # DETR ResNet-50
â”‚   â”‚   â”œâ”€â”€ depth.py           # Intel DPT-Large
â”‚   â”‚   â”œâ”€â”€ tts.py             # SpeechT5 + HiFiGAN
â”‚   â”‚   â””â”€â”€ translator.py      # MarianMT (5 languages)
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ analyze.py         # POST /analyze
â”‚       â”œâ”€â”€ voice.py           # POST /voice
â”‚       â””â”€â”€ health.py          # GET /health
â””â”€â”€ frontend/
    â””â”€â”€ src/
        â”œâ”€â”€ app/
        â”‚   â”œâ”€â”€ page.tsx       # Main analyzer page
        â”‚   â”œâ”€â”€ about/         # About + model info page
        â”‚   â”œâ”€â”€ layout.tsx
        â”‚   â””â”€â”€ globals.css
        â”œâ”€â”€ components/
        â”‚   â”œâ”€â”€ CameraCapture  # Webcam + file upload
        â”‚   â”œâ”€â”€ VoiceInput     # Mic â†’ Whisper
        â”‚   â”œâ”€â”€ DepthZoneMap   # 3-zone depth visual
        â”‚   â”œâ”€â”€ ResultPanel    # Full results display
        â”‚   â”œâ”€â”€ AudioPlayer    # TTS audio playback
        â”‚   â””â”€â”€ LanguageSelector
        â””â”€â”€ lib/api.ts         # Typed API client
```

---

## âš¡ Quick Start

### 1. Backend

```bash
cd backend

# Create virtual environment
python -m venv venv
venv\Scripts\activate          # Windows
# source venv/bin/activate     # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# (Optional) Pre-download all models
python download_models.py

# Start server
uvicorn main:app --reload --port 8000
```

Backend will be available at `http://localhost:8000`  
Swagger docs at `http://localhost:8000/docs`

### 2. Frontend

```bash
cd frontend
npm install
npm run dev
```

Frontend will be available at `http://localhost:3000`

---

## ğŸŒ API Reference

### `POST /analyze`
Analyze a scene image through the full AI pipeline.

**Request** (multipart/form-data):
| Field | Type | Description |
|---|---|---|
| `image` | File | JPEG / PNG / WebP image |
| `language` | string | `en`, `hi`, `fr`, `es`, `de`, `zh` |
| `query` | string | Optional spoken/typed question |

**Response** (JSON):
```json
{
  "description": "a busy street with people walking",
  "objects": [{"label": "person", "confidence": 0.98, "box": [...]}],
  "hazards": ["car", "person"],
  "depth": {
    "zones": {
      "left":   {"label": "Clear",      "percent": 12.0, "warning": "âœ… Path is clear"},
      "center": {"label": "Very Close", "percent": 81.0, "warning": "ğŸš¨ STOP"},
      "right":  {"label": "Medium",     "percent": 38.0, "warning": "ğŸŸ¡ Stay alert"}
    },
    "safe_to_walk": false
  },
  "translated_text": "...",
  "audio_b64": "<base64 WAV>",
  "safe_to_walk": false
}
```

### `POST /voice`
Transcribe audio via Whisper.

**Request**: multipart audio file (WAV / WebM)  
**Response**: `{"transcript": "Is it safe to walk forward?"}`

### `GET /health`
Returns model load status.

---

## ğŸ³ Docker (HuggingFace Spaces)

```bash
cd backend
docker build -t accessworld-backend .
docker run -p 7860:7860 accessworld-backend
```

---

## â™¿ Accessibility Commitments

- All interactive elements have ARIA labels
- Screen-reader friendly result announcements (`role="status"`, `aria-live`)
- Skip-to-content link for keyboard users
- High-contrast dark design (WCAG AA compliant colors)
- Full keyboard navigation support
